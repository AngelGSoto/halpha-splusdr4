<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-06-10 Tue 09:50 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Rigorous Mathematical Proof of the Error Propagation Method in S-PLUS Hα-Excess Analysis</title>
<meta name="author" content="Luis A. Gutiérrez Soto et al." />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
</style>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Rigorous Mathematical Proof of the Error Propagation Method in S-PLUS Hα-Excess Analysis</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org1b11375">1. Mathematical Derivation</a>
<ul>
<li><a href="#org0816989">1.1. Variable Definitions</a></li>
<li><a href="#org7fe50bb">1.2. Derivation of the Ideal Method from First Principles</a>
<ul>
<li><a href="#orgcbe4bef">1.2.1. Definition of Residual</a></li>
<li><a href="#orgefd173e">1.2.2. Error Propagation Formula</a></li>
<li><a href="#org0aedb47">1.2.3. Partial Derivatives</a></li>
<li><a href="#org871b19e">1.2.4. Substitute Derivatives into Error Propagation</a></li>
</ul>
</li>
<li><a href="#org9d8786c">1.3. Error Propagation Equations</a>
<ul>
<li><a href="#org9451b1b">1.3.1. Classical Method</a></li>
<li><a href="#org6ccc7fc">1.3.2. Luis's Method (Proposed)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org829763d">2. Simplified error estimate</a></li>
</ul>
</div>
</div>



<div id="outline-container-org1b11375" class="outline-2">
<h2 id="org1b11375"><span class="section-number-2">1.</span> Mathematical Derivation</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org0816989" class="outline-3">
<h3 id="org0816989"><span class="section-number-3">1.1.</span> Variable Definitions</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>\( m \): Slope of the stellar locus in the \((r - i)\) vs. \((r - J0660)\) diagram.</li>
<li>\( \sigma_s \): RMS of residuals from the linear fit.</li>
<li>\( \sigma_{(r-J0660)} = \sqrt{\sigma_r^2 + \sigma_{J0660}^2} \): Error of the color \((r - J0660)\).</li>
<li>\( \sigma_{(r-i)} = \sqrt{\sigma_r^2 + \sigma_i^2} \): Error of the color \((r - i)\).</li>
</ul>
</div>
</div>

<div id="outline-container-org7fe50bb" class="outline-3">
<h3 id="org7fe50bb"><span class="section-number-3">1.2.</span> Derivation of the Ideal Method from First Principles</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-orgcbe4bef" class="outline-4">
<h4 id="orgcbe4bef"><span class="section-number-4">1.2.1.</span> Definition of Residual</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
The residual between the observed and fitted colors is:
\[
\text{Residual} = (r - J0660)_{\text{obs}} - (r - J0660)_{\text{fit}}
\]
where the fitted color follows the linear relation:
\[
(r - J0660)_{\text{fit}} = m \cdot (r - i) + b
\]
Substituting \((r - i) = r_{\text{obs}} - i_{\text{obs}}\):
\[
\text{Residual} = (r_{\text{obs}} - J0660_{\text{obs}}) - \left[m \cdot (r_{\text{obs}} - i_{\text{obs}}) + b\right]
\]
Simplifying:
\[
\text{Residual} = (1 - m)r_{\text{obs}} - J0660_{\text{obs}} + m \cdot i_{\text{obs}} - b
\]
</p>
</div>
</div>

<div id="outline-container-orgefd173e" class="outline-4">
<h4 id="orgefd173e"><span class="section-number-4">1.2.2.</span> Error Propagation Formula</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
The total uncertainty in the residual is:
\[
\sigma_{\text{est}}^2 = \sigma_s^2 + \sum_{x} \left(\frac{\partial \text{Residual}}{\partial x}\right)^2 \sigma_x^2
\]
where \( x = r, i, J0660 \).
</p>
</div>
</div>

<div id="outline-container-org0aedb47" class="outline-4">
<h4 id="org0aedb47"><span class="section-number-4">1.2.3.</span> Partial Derivatives</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
\[
</p>
\begin{aligned}
\frac{\partial \text{Residual}}{\partial r} &= 1 - m \\
\frac{\partial \text{Residual}}{\partial i} &= m \\
\frac{\partial \text{Residual}}{\partial J0660} &= -1 \\
\frac{\partial \text{Residual}}{\partial b} &= -1 \quad (\text{absorbed into } \sigma_s) \\
\end{aligned}
<p>
\]
</p>
</div>
</div>

<div id="outline-container-org871b19e" class="outline-4">
<h4 id="org871b19e"><span class="section-number-4">1.2.4.</span> Substitute Derivatives into Error Propagation</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
\[
\sigma_{\text{est}}^2 = \sigma_s^2 + (1 - m)^2 \sigma_r^2 + m^2 \sigma_i^2 + (-1)^2 \sigma_{J0660}^2
\]
\[
\Rightarrow \boxed{\sigma_{\text{est, ideal}}^2 = \sigma_s^2 + (1 - m)^2 \sigma_r^2 + \sigma_{J0660}^2 + m^2 \sigma_i^2}
\]
</p>
</div>
</div>
</div>

<div id="outline-container-org9d8786c" class="outline-3">
<h3 id="org9d8786c"><span class="section-number-3">1.3.</span> Error Propagation Equations</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org9451b1b" class="outline-4">
<h4 id="org9451b1b"><span class="section-number-4">1.3.1.</span> Classical Method</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
Now, we try to writte the equation similar those used in Witham et al. (2206);
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + (1 - 2m + m^2) \sigma_r^2 + \sigma_{J0660}^2 + m^2 \sigma_i^2
\]
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_r^2 - 2m \sigma_r^2 + m^2 \sigma_r^2 + \sigma_{J0660}^2 + m^2 \sigma_i^2
\]
</p>

<p>
Rearranging terms;
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_r^2 + \sigma_{J0660}^2 - 2m \sigma_r^2 + m^2 \sigma_r^2  + m^2 \sigma_i^2
\]
</p>

<p>
Given  \(\sigma_x^2 + \sigma_y^2 = \sigma_{(x - y)}^2 \) then;
</p>


<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_{r - J0660}^2 +  m^2 \sigma_{r - i}^2 - 2m \sigma_r^2 
\]
</p>

<p>
So, to obtain the equation from Witham et al., we have to remove the contribution of the \(- 2m \sigma_r^2\) term. How much does this term contribute?
</p>


<p>
\[
\sigma_{\text{est, classical}}^2 = \sigma_s^2 + \sigma_{(r-J0660)}^2 + m^2 \sigma_{(r-i)}^2
\]
Go back to the individual error bands:
\[
\sigma_{\text{est, classical}}^2 = \sigma_s^2 + (\sigma_r^2 + \sigma_{J0660}^2) + m^2 (\sigma_r^2 + \sigma_i^2)
\]
\[
= \sigma_s^2 + \sigma_r^2(1 + m^2) + \sigma_{J0660}^2 + m^2 \sigma_i^2 \quad \text{(Overcounts } \sigma_r^2 \text{)}
\]
</p>

<p>
Now we do some numerical examples. I note to the slope of the fits in the color-color diagram  in most of the case is between 0.35 - 0.4, used in this case 0.4 for the slope:
</p>

<table id="org10f33a4" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">e<sub>r</sub><sub>PStotal</sub></th>
<th scope="col" class="org-right">e<sub>i</sub><sub>PStotal</sub></th>
<th scope="col" class="org-right">e<sub>J0660</sub><sub>PStotal</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0.0027043421</td>
<td class="org-right">0.002309852</td>
<td class="org-right">0.0034417643</td>
</tr>

<tr>
<td class="org-right">0.0009554346</td>
<td class="org-right">0.0010019763</td>
<td class="org-right">0.0010847448</td>
</tr>

<tr>
<td class="org-right">0.0016022029</td>
<td class="org-right">0.0014943366</td>
<td class="org-right">0.0017039843</td>
</tr>

<tr>
<td class="org-right">0.0022326636</td>
<td class="org-right">0.0020145355</td>
<td class="org-right">0.0023408893</td>
</tr>

<tr>
<td class="org-right">0.00428348</td>
<td class="org-right">0.0026568426</td>
<td class="org-right">0.004832741</td>
</tr>

<tr>
<td class="org-right">0.0008637211</td>
<td class="org-right">0.0008142423</td>
<td class="org-right">0.0009804317</td>
</tr>

<tr>
<td class="org-right">0.0037895583</td>
<td class="org-right">0.0036628896</td>
<td class="org-right">0.0044751875</td>
</tr>

<tr>
<td class="org-right">0.0026341775</td>
<td class="org-right">0.0025405292</td>
<td class="org-right">0.0020656579</td>
</tr>

<tr>
<td class="org-right">0.0011333079</td>
<td class="org-right">0.0010817236</td>
<td class="org-right">0.0010882834</td>
</tr>

<tr>
<td class="org-right">0.0013017068</td>
<td class="org-right">0.0012364228</td>
<td class="org-right">0.0009283392</td>
</tr>

<tr>
<td class="org-right">0.0032339918</td>
<td class="org-right">0.0032643287</td>
<td class="org-right">0.0035206582</td>
</tr>

<tr>
<td class="org-right">0.0015321858</td>
<td class="org-right">0.0014926838</td>
<td class="org-right">0.0017911163</td>
</tr>

<tr>
<td class="org-right">0.0023779713</td>
<td class="org-right">0.0022736047</td>
<td class="org-right">0.0022346096</td>
</tr>

<tr>
<td class="org-right">0.003833847</td>
<td class="org-right">0.003391762</td>
<td class="org-right">0.0039768526</td>
</tr>

<tr>
<td class="org-right">0.0032339613</td>
<td class="org-right">0.0026312915</td>
<td class="org-right">0.0031807977</td>
</tr>

<tr>
<td class="org-right">0.0024073187</td>
<td class="org-right">0.0020921866</td>
<td class="org-right">0.002365463</td>
</tr>

<tr>
<td class="org-right">0.0029173244</td>
<td class="org-right">0.0024788384</td>
<td class="org-right">0.0036630423</td>
</tr>

<tr>
<td class="org-right">0.0023025507</td>
<td class="org-right">0.0022479515</td>
<td class="org-right">0.0026816207</td>
</tr>

<tr>
<td class="org-right">0.0023555679</td>
<td class="org-right">0.0023168672</td>
<td class="org-right">0.002819191</td>
</tr>

<tr>
<td class="org-right">0.0033654603</td>
<td class="org-right">0.0033328792</td>
<td class="org-right">0.0038815523</td>
</tr>

<tr>
<td class="org-right">0.0025632957</td>
<td class="org-right">0.0023379133</td>
<td class="org-right">0.0025938326</td>
</tr>

<tr>
<td class="org-right">0.00349301</td>
<td class="org-right">0.003411095</td>
<td class="org-right">0.003810881</td>
</tr>

<tr>
<td class="org-right">0.0030717351</td>
<td class="org-right">0.0030049048</td>
<td class="org-right">0.0032032381</td>
</tr>

<tr>
<td class="org-right">0.001193243</td>
<td class="org-right">0.0011562117</td>
<td class="org-right">0.0009968877</td>
</tr>

<tr>
<td class="org-right">0.0013465676</td>
<td class="org-right">0.0013025336</td>
<td class="org-right">0.0008975989</td>
</tr>

<tr>
<td class="org-right">0.0013131873</td>
<td class="org-right">0.0011755121</td>
<td class="org-right">0.00084322726</td>
</tr>

<tr>
<td class="org-right">0.0013177483</td>
<td class="org-right">0.0012559775</td>
<td class="org-right">0.0008621476</td>
</tr>

<tr>
<td class="org-right">0.0012351323</td>
<td class="org-right">0.0011085502</td>
<td class="org-right">0.0008751316</td>
</tr>

<tr>
<td class="org-right">0.0012229811</td>
<td class="org-right">0.0011141312</td>
<td class="org-right">0.00087049545</td>
</tr>

<tr>
<td class="org-right">0.001374798</td>
<td class="org-right">0.0013328108</td>
<td class="org-right">0.0009173866</td>
</tr>

<tr>
<td class="org-right">0.0013861168</td>
<td class="org-right">0.001221707</td>
<td class="org-right">0.0008832612</td>
</tr>

<tr>
<td class="org-right">0.0025332794</td>
<td class="org-right">0.002932436</td>
<td class="org-right">0.0027128041</td>
</tr>

<tr>
<td class="org-right">0.0036067879</td>
<td class="org-right">0.0031376323</td>
<td class="org-right">0.0037044238</td>
</tr>

<tr>
<td class="org-right">0.00339293</td>
<td class="org-right">0.0033208467</td>
<td class="org-right">0.004346304</td>
</tr>

<tr>
<td class="org-right">0.0014183201</td>
<td class="org-right">0.0013238328</td>
<td class="org-right">0.0016154384</td>
</tr>

<tr>
<td class="org-right">0.004621427</td>
<td class="org-right">0.0047028367</td>
<td class="org-right">0.0046202843</td>
</tr>

<tr>
<td class="org-right">0.0014658732</td>
<td class="org-right">0.0013899308</td>
<td class="org-right">0.00256149</td>
</tr>

<tr>
<td class="org-right">0.0023711754</td>
<td class="org-right">0.0022108082</td>
<td class="org-right">0.0026406425</td>
</tr>

<tr>
<td class="org-right">0.002516076</td>
<td class="org-right">0.0023366914</td>
<td class="org-right">0.002748363</td>
</tr>

<tr>
<td class="org-right">0.0019471686</td>
<td class="org-right">0.0018115259</td>
<td class="org-right">0.004527632</td>
</tr>

<tr>
<td class="org-right">0.0033787978</td>
<td class="org-right">0.0030290852</td>
<td class="org-right">0.003503075</td>
</tr>

<tr>
<td class="org-right">0.0021783817</td>
<td class="org-right">0.0021271813</td>
<td class="org-right">0.0019475339</td>
</tr>

<tr>
<td class="org-right">0.0036444226</td>
<td class="org-right">0.0033581583</td>
<td class="org-right">0.003897624</td>
</tr>

<tr>
<td class="org-right">0.002823925</td>
<td class="org-right">0.0026747882</td>
<td class="org-right">0.003112585</td>
</tr>

<tr>
<td class="org-right">0.0035756512</td>
<td class="org-right">0.0033058396</td>
<td class="org-right">0.00492577</td>
</tr>

<tr>
<td class="org-right">0.0034714018</td>
<td class="org-right">0.003403292</td>
<td class="org-right">0.0038095748</td>
</tr>

<tr>
<td class="org-right">0.0029721686</td>
<td class="org-right">0.0027480372</td>
<td class="org-right">0.0029622987</td>
</tr>

<tr>
<td class="org-right">0.002644481</td>
<td class="org-right">0.0026835275</td>
<td class="org-right">0.0025978298</td>
</tr>

<tr>
<td class="org-right">0.0028707138</td>
<td class="org-right">0.002735543</td>
<td class="org-right">0.0032248157</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>Calculating overestimation</li>
</ul>
<p>
Use this Python block to compute and render the table plus mean/median when exporting to HTML:
</p>

<div class="org-src-container">
<pre class="src src-python" id="org92f067d"><span style="color: #00ffff;">import</span> numpy <span style="color: #00ffff;">as</span> np

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Header row</span>
<span style="color: #eedd82;">header</span> = [<span style="color: #ffa07a;">"e_r"</span>, <span style="color: #ffa07a;">"e_i"</span>, <span style="color: #ffa07a;">"e_J0660"</span>, <span style="color: #ffa07a;">"&#963;_ideal"</span>, <span style="color: #ffa07a;">"&#963;_classic"</span>, <span style="color: #ffa07a;">"Overestimation (%)"</span>]
<span style="color: #eedd82;">new_table</span> = []
<span style="color: #eedd82;">overest</span> = []

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Process each data row</span>
<span style="color: #00ffff;">for</span> sr_str, si_str, sj_str <span style="color: #00ffff;">in</span> <span style="color: #eedd82;">data</span>:
    <span style="color: #00ffff;">try</span>:
        sr = <span style="color: #b0c4de;">float</span>(sr_str)
        <span style="color: #eedd82;">si</span> = <span style="color: #b0c4de;">float</span>(si_str)
        <span style="color: #eedd82;">sj</span> = <span style="color: #b0c4de;">float</span>(sj_str)
        <span style="color: #eedd82;">&#963;_ideal</span>   = np.sqrt(sigma_s**2 + (1 - m)**2 * sr**2 + sj**2 + m**2 * si**2)
        <span style="color: #eedd82;">&#963;_classic</span> = np.sqrt(sigma_s**2 + (sr**2 + sj**2) + m**2 * (sr**2 + si**2))
        <span style="color: #eedd82;">pct</span> = (&#963;_classic - &#963;_ideal) / &#963;_ideal * 100
        new_table.append([f<span style="color: #ffa07a;">"</span>{sr:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{si:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{sj:.7f}<span style="color: #ffa07a;">"</span>,
                          f<span style="color: #ffa07a;">"</span>{&#963;_ideal:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{&#963;_classic:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{pct:.2f}<span style="color: #ffa07a;">%"</span>])
        overest.append(pct)
    <span style="color: #00ffff;">except</span>:
        new_table.append([sr_str, si_str, sj_str, <span style="color: #ffa07a;">"Error"</span>, <span style="color: #ffa07a;">"Error"</span>, <span style="color: #ffa07a;">"Error"</span>])

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Add summary rows</span>
mean_pct   = np.mean(overest)
<span style="color: #eedd82;">median_pct</span> = np.median(overest)
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Mean"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, f<span style="color: #ffa07a;">"</span>{mean_pct:.2f}<span style="color: #ffa07a;">%"</span>])
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Median"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, f<span style="color: #ffa07a;">"</span>{median_pct:.2f}<span style="color: #ffa07a;">%"</span>])

<span style="color: #00ffff;">return</span> [header] + new_table
</pre>
</div>

<p>
The classical estimation of σσ results in an overestimation of about 2.32%, considering m=0.4,
which is typical for the fit in the stellar locus color–color diagram of S-PLUS, and assuming sigma<sub>ss</sub>=0.01.
</p>
</div>
</div>

<div id="outline-container-org6ccc7fc" class="outline-4">
<h4 id="org6ccc7fc"><span class="section-number-4">1.3.2.</span> Luis's Method (Proposed)</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
See if I get a better apprximation on wich the covariance term contribute lees to the sigma value. Go back again to the ideal case:
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_r^2 + \sigma_{J0660}^2 - 2m \sigma_r^2 + m^2 \sigma_r^2  + m^2 \sigma_i^2
\]
</p>

<p>
Rearrange;
</p>

<p>
\[
\Rightarrow \boxed{\sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_r^2 + \sigma_{J0660}^2 + m^2 (\sigma_r^2  + \sigma_i^2}) - 2m \sigma_r^2
\]
</p>

<p>
Add and subtract the term: \(-2m(\sigma_r^2 + \sigma_{J0660}^2) + m^2(\sigma_r^2 + \sigma_{J0660}^2\), then:
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + \sigma_r^2 + \sigma_{J0660}^2 + m^2 (\sigma_r^2  + \sigma_i^2) - 2m \sigma_r^2 + (-2m(\sigma_r^2 + \sigma_{J0660}^2)+ m^2(\sigma_r^2 + \sigma_{J0660}^2)) - (-2m(\sigma_r^2 + \sigma_{J0660}^2)+ m^2(\sigma_r^2 + \sigma_{J0660}^2))
\]
</p>

<p>
Next, we rearrange and factorize:
</p>

<p>
\[
\Rightarrow \sigma_{\text{est, ideal}}^2 = \sigma_s^2 + (1 - 2m + m^2)(\sigma_r^2 + \sigma_{J0660}^2) + m^2 (\sigma_r^2  + \sigma_i^2) - 2m \sigma_r^2 - (-2m(\sigma_r^2 + \sigma_{J0660}^2) + m^2(\sigma_r^2 + \sigma_{J0660}^2))
\]
</p>

<p>
\[
\Rightarrow \boxed{\sigma_{\text{est, ideal}}^2 = \sigma_s^2 + (1 - m)^2(\sigma_r^2 + \sigma_{J0660}^2) + m^2 (\sigma_r^2  + \sigma_i^2}) + 2m\sigma_{J0660}^2 - m^2 \sigma_r^2 - m^2 \sigma_{J0660}^2
\]
</p>

<p>
\( \Rightarrow \sigma_{\mathrm{est,ideal}}^2 = \sigma_s^2 + (1 - m)^2(\sigma_r^2 + \sigma_{J0660}^2) + m^2(\sigma_r^2 + \sigma_i^2) - m^2\sigma_r^2 - m^2\sigma_{J0660}^2 + 2m\,\sigma_{J0660}^2 \)
</p>

<p>
\( \Rightarrow \sigma_{\mathrm{est,ideal}}^2 = \sigma_s^2 + (1 - m)^2(\sigma_r^2 + \sigma_{J0660}^2) + m^2(\sigma_r^2 + \sigma_i^2) - m^2\sigma_r^2 + (2m - m^2)\,\sigma_{J0660}^2 \)
</p>


<p>
The covariance term is: \(-m^2 \sigma_r^2 + (2m - m^2) \sigma_{J0660}^2\). Therefore, <b><b>the contribution</b></b> of this term is:
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org829763d" class="outline-2">
<h2 id="org829763d"><span class="section-number-2">2.</span> Simplified error estimate</h2>
<div class="outline-text-2" id="text-2">
<p>
By removing the covariance term, we keep only the color errors:
</p>

<p>
\( \sigma_{\mathrm{est,Luis}}^2 = \sigma_s^2 + (1 - m)^2\,\sigma_{(r - J0660)}^2 + m^2\,\sigma_{(r - i)}^2 \)
</p>

<p>
Contribution of the Removed Covariance Term
</p>


<div class="org-src-container">
<pre class="src src-python" id="orgae32354"><span style="color: #00ffff;">import</span> numpy <span style="color: #00ffff;">as</span> np

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Header row</span>
<span style="color: #eedd82;">header</span> = [<span style="color: #ffa07a;">"e_r"</span>, <span style="color: #ffa07a;">"e_i"</span>, <span style="color: #ffa07a;">"e_J0660"</span>, <span style="color: #ffa07a;">"&#963;_ideal"</span>, <span style="color: #ffa07a;">"&#963;_luis"</span>, <span style="color: #ffa07a;">"Overestimation (%)"</span>]
<span style="color: #eedd82;">new_table</span> = []
<span style="color: #eedd82;">overest</span> = []

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Process each data row</span>
<span style="color: #00ffff;">for</span> sr_str, si_str, sj_str <span style="color: #00ffff;">in</span> <span style="color: #eedd82;">data</span>:
    <span style="color: #00ffff;">try</span>:
        sr = <span style="color: #b0c4de;">float</span>(sr_str)
        <span style="color: #eedd82;">si</span> = <span style="color: #b0c4de;">float</span>(si_str)
        <span style="color: #eedd82;">sj</span> = <span style="color: #b0c4de;">float</span>(sj_str)

        <span style="color: #eedd82;">&#963;_ideal</span> = np.sqrt(
            sigma_s**2 +
            (1 - m)**2 * sr**2 +
            sj**2 +
            m**2 * si**2
        )
        <span style="color: #eedd82;">&#963;_luis</span> = np.sqrt(
            sigma_s**2 +
            (1 - m)**2 * (sr**2 + sj**2) +
            m**2 * (sr**2 + si**2)
        )

        <span style="color: #eedd82;">pct</span> = (&#963;_luis - &#963;_ideal) / &#963;_ideal * 100
        new_table.append([
            f<span style="color: #ffa07a;">"</span>{sr:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{si:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{sj:.7f}<span style="color: #ffa07a;">"</span>,
            f<span style="color: #ffa07a;">"</span>{&#963;_ideal:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{&#963;_luis:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{pct:.2f}<span style="color: #ffa07a;">%"</span>
        ])
        overest.append(pct)
    <span style="color: #00ffff;">except</span>:
        new_table.append([sr_str, si_str, sj_str, <span style="color: #ffa07a;">"Error"</span>, <span style="color: #ffa07a;">"Error"</span>, <span style="color: #ffa07a;">"Error"</span>])

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Add summary rows</span>
mean_pct   = np.mean(overest)
<span style="color: #eedd82;">median_pct</span> = np.median(overest)
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Mean"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, f<span style="color: #ffa07a;">"</span>{mean_pct:.2f}<span style="color: #ffa07a;">%"</span>])
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Median"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, f<span style="color: #ffa07a;">"</span>{median_pct:.2f}<span style="color: #ffa07a;">%"</span>])

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Return full table</span>
<span style="color: #00ffff;">return</span> [header] + new_table
</pre>
</div>

<p>
The luis aproximation subestima the sigma in around -1.85%.
</p>
</div>

<ol class="org-ol">
<li><a id="org5ab1cc9"></a>Classic versus Luis aproximation<br />
<div class="outline-text-5" id="text-2-0-0-1">
<p>
Now Comparing Classic vs. Luis Overestimation
</p>

<div class="org-src-container">
<pre class="src src-python" id="orgb948f4f"><span style="color: #00ffff;">import</span> numpy <span style="color: #00ffff;">as</span> np

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Header row</span>
<span style="color: #eedd82;">header</span> = [
    <span style="color: #ffa07a;">"e_r"</span>, <span style="color: #ffa07a;">"e_i"</span>, <span style="color: #ffa07a;">"e_J0660"</span>,
    <span style="color: #ffa07a;">"&#963;_ideal"</span>, <span style="color: #ffa07a;">"&#963;_classic"</span>, <span style="color: #ffa07a;">"&#963;_luis"</span>,
    <span style="color: #ffa07a;">"Classic overestimation (%)"</span>, <span style="color: #ffa07a;">"Luis overestimation (%)"</span>
]

<span style="color: #eedd82;">new_table</span> = []
<span style="color: #eedd82;">overest_classic</span> = []
<span style="color: #eedd82;">overest_luis</span> = []

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Process each data row</span>
<span style="color: #00ffff;">for</span> sr_str, si_str, sj_str <span style="color: #00ffff;">in</span> <span style="color: #eedd82;">data</span>:
    <span style="color: #00ffff;">try</span>:
        sr = <span style="color: #b0c4de;">float</span>(sr_str)
        <span style="color: #eedd82;">si</span> = <span style="color: #b0c4de;">float</span>(si_str)
        <span style="color: #eedd82;">sj</span> = <span style="color: #b0c4de;">float</span>(sj_str)

        <span style="color: #eedd82;">&#963;_ideal</span>   = np.sqrt(
            sigma_s**2 +
            (1 - m)**2 * sr**2 +
            sj**2 +
            m**2 * si**2
        )
        <span style="color: #eedd82;">&#963;_classic</span> = np.sqrt(
            sigma_s**2 +
            (sr**2 + sj**2) +
            m**2 * (sr**2 + si**2)
        )
        <span style="color: #eedd82;">&#963;_luis</span>    = np.sqrt(
            sigma_s**2 +
            (1 - m)**2 * (sr**2 + sj**2) +
            m**2 * (sr**2 + si**2)
        )

        <span style="color: #eedd82;">pct_classic</span> = (&#963;_classic - &#963;_ideal) / &#963;_ideal * 100
        <span style="color: #eedd82;">pct_luis</span>    = (&#963;_luis    - &#963;_ideal) / &#963;_ideal * 100

        new_table.append([
            f<span style="color: #ffa07a;">"</span>{sr:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{si:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{sj:.7f}<span style="color: #ffa07a;">"</span>,
            f<span style="color: #ffa07a;">"</span>{&#963;_ideal:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{&#963;_classic:.7f}<span style="color: #ffa07a;">"</span>, f<span style="color: #ffa07a;">"</span>{&#963;_luis:.7f}<span style="color: #ffa07a;">"</span>,
            f<span style="color: #ffa07a;">"</span>{pct_classic:.2f}<span style="color: #ffa07a;">%"</span>, f<span style="color: #ffa07a;">"</span>{pct_luis:.2f}<span style="color: #ffa07a;">%"</span>
        ])
        overest_classic.append(pct_classic)
        overest_luis.append(pct_luis)

    <span style="color: #00ffff;">except</span>:
        new_table.append([sr_str, si_str, sj_str] + [<span style="color: #ffa07a;">"Error"</span>] * 5)

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Compute summary statistics</span>
<span style="color: #eedd82;">mean_c</span>   = np.mean(overest_classic)
<span style="color: #eedd82;">median_c</span> = np.median(overest_classic)
<span style="color: #eedd82;">min_c</span>    = np.<span style="color: #b0c4de;">min</span>(overest_classic)
<span style="color: #eedd82;">max_c</span>    = np.<span style="color: #b0c4de;">max</span>(overest_classic)

<span style="color: #eedd82;">mean_l</span>   = np.mean(overest_luis)
<span style="color: #eedd82;">median_l</span> = np.median(overest_luis)
<span style="color: #eedd82;">min_l</span>    = np.<span style="color: #b0c4de;">min</span>(overest_luis)
<span style="color: #eedd82;">max_l</span>    = np.<span style="color: #b0c4de;">max</span>(overest_luis)

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Append summary rows</span>
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Mean"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>,
                  f<span style="color: #ffa07a;">"</span>{mean_c:.2f}<span style="color: #ffa07a;">%"</span>, f<span style="color: #ffa07a;">"</span>{mean_l:.2f}<span style="color: #ffa07a;">%"</span>])
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Median"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>,
                  f<span style="color: #ffa07a;">"</span>{median_c:.2f}<span style="color: #ffa07a;">%"</span>, f<span style="color: #ffa07a;">"</span>{median_l:.2f}<span style="color: #ffa07a;">%"</span>])
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Min"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>,
                  f<span style="color: #ffa07a;">"</span>{min_c:.2f}<span style="color: #ffa07a;">%"</span>, f<span style="color: #ffa07a;">"</span>{min_l:.2f}<span style="color: #ffa07a;">%"</span>])
new_table.append([<span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">"Max"</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>, <span style="color: #ffa07a;">""</span>,
                  f<span style="color: #ffa07a;">"</span>{max_c:.2f}<span style="color: #ffa07a;">%"</span>, f<span style="color: #ffa07a;">"</span>{max_l:.2f}<span style="color: #ffa07a;">%"</span>])

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Return full table</span>
<span style="color: #00ffff;">return</span> [header] + new_table
</pre>
</div>

<p>
Clearly, Luis’s approximation is closer to the ideal case, underestimating by only about 1.85%, compared to the classical method, which overestimates by approximately 2.33%.
</p>

<p>
Now estimate the value of the covariance term for both case:
</p>

<div class="org-src-container">
<pre class="src src-python" id="org92d3e4c"><span style="color: #00ffff;">import</span> numpy <span style="color: #00ffff;">as</span> np

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Header for the output table</span>
<span style="color: #eedd82;">header</span> = [<span style="color: #ffa07a;">"e_r"</span>, <span style="color: #ffa07a;">"e_i"</span>, <span style="color: #ffa07a;">"e_J0660"</span>, <span style="color: #ffa07a;">"Cov_classic"</span>, <span style="color: #ffa07a;">"Cov_Luis"</span>]
<span style="color: #eedd82;">output</span> = []

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Compute covariance terms for each row</span>
<span style="color: #00ffff;">for</span> sr_str, si_str, sj_str <span style="color: #00ffff;">in</span> <span style="color: #eedd82;">data</span>:
    <span style="color: #00ffff;">try</span>:
        sr = <span style="color: #b0c4de;">float</span>(sr_str)
        <span style="color: #eedd82;">sj</span> = <span style="color: #b0c4de;">float</span>(sj_str)
        <span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Classical covariance term</span>
        <span style="color: #eedd82;">cov_classic</span> = -2 * m * sr**2
        <span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Luis covariance term</span>
        <span style="color: #eedd82;">cov_luis</span> = -m**2 * sr**2 + (2 * m - m**2) * sj**2

        output.append([
            f<span style="color: #ffa07a;">"</span>{sr:.7f}<span style="color: #ffa07a;">"</span>,
            si_str,
            f<span style="color: #ffa07a;">"</span>{sj:.7f}<span style="color: #ffa07a;">"</span>,
            f<span style="color: #ffa07a;">"</span>{cov_classic:.7e}<span style="color: #ffa07a;">"</span>,
            f<span style="color: #ffa07a;">"</span>{cov_luis:.7e}<span style="color: #ffa07a;">"</span>
        ])
    <span style="color: #00ffff;">except</span> <span style="color: #98fb98;">Exception</span>:
        output.append([sr_str, si_str, sj_str, <span style="color: #ffa07a;">"Error"</span>, <span style="color: #ffa07a;">"Error"</span>])

<span style="color: #ff7f24;"># </span><span style="color: #ff7f24;">Return header + computed rows</span>
<span style="color: #00ffff;">return</span> [header] + output
</pre>
</div>

<p>
The comparison between the classical covariance and the alternative method implemented by
Luis reveals that the latter consistently yields values closer to zero. This indicates
a weaker linear dependency between the photometric errors of the \(r\), \(i\), and \(J0660\) filters.
A covariance closer to zero suggests that the method proposed by Luis more effectively minimizes
spurious correlations among uncertainties, bringing the error structure closer to the ideal
assumption of independence. Therefore, the "Cov<sub>Luis</sub>" approach provides
a more reliable representation of the photometric error relationships in this context.
</p>
</div>
</li>
</ol>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Luis A. Gutiérrez Soto et al.</p>
<p class="date">Created: 2025-06-10 Tue 09:50</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
